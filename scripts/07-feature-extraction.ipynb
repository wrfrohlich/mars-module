{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import statistics\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from biosppy import signals as bio_signals\n",
    "from scipy.stats import norm, kurtosis, skew\n",
    "from scipy.signal import find_peaks,peak_widths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = 'binary'\n",
    "#classification = 'selected'\n",
    "\n",
    "project = 'athena-i'\n",
    "train_file = 'wind-train-'\n",
    "new_train_file = 'feature-train-'\n",
    "\n",
    "size = 150\n",
    "\n",
    "dataset_path = \"%s/%s/dataset/%s/\" % (os.getenv('HOME'), project, classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Functions and Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path, file):\n",
    "    x_train = pd.read_csv('%s%sx' % (path, file), delimiter=';')\n",
    "    y_train = pd.read_csv('%s%sy' % (path, file), delimiter=';')\n",
    "        \n",
    "    return(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmssd(list):\n",
    "    diff_nni = np.diff(list)#successive differences\n",
    "    return np.sqrt(np.mean(diff_nni ** 2))\n",
    "\n",
    "#independent function to calculate AVRR   \n",
    "def avrr(list):\n",
    "    return sum(list)/len(list)\n",
    "\n",
    "#independent function to calculate SDRR   \n",
    "def csdrr(list):\n",
    "    return statistics.stdev(list)\n",
    "    \n",
    "def pNNx(list):\n",
    "    length_int = len(list)\n",
    "    diff_nni = np.diff(list)\n",
    "    nni_50 = sum(np.abs(diff_nni) > 50)\n",
    "    return 100 * nni_50 / length_int\n",
    "\n",
    "#independent function to calculate SD1\n",
    "def SD1(list):\n",
    "    diff_nn_intervals = np.diff(list)\n",
    "    return np.sqrt(np.std(diff_nn_intervals, ddof=1) ** 2 * 0.5)\n",
    "\n",
    "#independent function to calculate SD2\n",
    "def SD2(list):\n",
    "    diff_nn_intervals = np.diff(list)\n",
    "    return np.sqrt(2 * np.std(list, ddof=1) ** 2 - 0.5 * np.std(\\\n",
    "                   diff_nn_intervals, ddof=1) ** 2)\n",
    "    \n",
    "#independent function to calculate SD1/SD2\n",
    "def SD1overSD2(list):\n",
    "    diff_nn_intervals = np.diff(list)\n",
    "    sd1 = np.sqrt(np.std(diff_nn_intervals, ddof=1) ** 2 * 0.5)\n",
    "    sd2 = np.sqrt(2 * np.std(list, ddof=1) ** 2 - 0.5 * np.std(\\\n",
    "                    diff_nn_intervals, ddof=1) ** 2)\n",
    "    ratio_sd2_sd1 = sd2 / sd1\n",
    "    return ratio_sd2_sd1\n",
    "    \n",
    "    \n",
    "#independent function to calculate CSI\n",
    "def CSI(list):\n",
    "    diff_nn_intervals = np.diff(list)\n",
    "    sd1 = np.sqrt(np.std(diff_nn_intervals, ddof=1) ** 2 * 0.5)\n",
    "    sd2 = np.sqrt(2 * np.std(list, ddof=1) ** 2 - 0.5 * np.std(\\\n",
    "                  diff_nn_intervals, ddof=1) ** 2)\n",
    "    L=4 * sd1\n",
    "    T=4 * sd2\n",
    "    return L/T\n",
    "       \n",
    "#independent function to calculate CVI\n",
    "def CVI(list):\n",
    "    diff_nn_intervals = np.diff(list)\n",
    "    sd1 = np.sqrt(np.std(diff_nn_intervals, ddof=1) ** 2 * 0.5)\n",
    "    sd2 = np.sqrt(2 * np.std(list, ddof=1) ** 2 - 0.5 * np.std(\\\n",
    "                  diff_nn_intervals, ddof=1) ** 2)\n",
    "    L=4 * sd1\n",
    "    T=4 * sd2\n",
    "    return np.log10(L * T)\n",
    " \n",
    "#independent function to calculate modified CVI\n",
    "def modifiedCVI(list):\n",
    "    diff_nn_intervals = np.diff(list)\n",
    "    sd1 = np.sqrt(np.std(diff_nn_intervals, ddof=1) ** 2 * 0.5)\n",
    "    sd2 = np.sqrt(2 * np.std(list, ddof=1) ** 2 - 0.5 * np.std(\\\n",
    "                  diff_nn_intervals, ddof=1) ** 2)\n",
    "    L=4 * sd1\n",
    "    T=4 * sd2\n",
    "    return L ** 2 / T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Absolute Value (MAV)\n",
    "def featureMAV(data):\n",
    "    return np.mean(np.abs(data), axis=0) \n",
    "\n",
    "# Root Mean Square (RMS)\n",
    "def featureRMS(data):\n",
    "    return np.sqrt(np.mean(data**2, axis=0))\n",
    "\n",
    "# Log Root Mean Square (RMS)\n",
    "def featureLRMS(data):\n",
    "    return np.log(np.sqrt(np.mean(data**2, axis=0)))\n",
    "\n",
    "# Waveform length (WL) \n",
    "def featureWL(data):\n",
    "    return np.sum(np.abs(np.diff(data, axis=0)),axis=0)/data.shape[0]\n",
    "\n",
    "# Kurtosis (KUR)\n",
    "def featureKUR(data):\n",
    "    #data = norm.rvs(size=1000, random_state=3)\n",
    "    return kurtosis(data)\n",
    "\n",
    "# Skewness (SKEW)\n",
    "def featureSKEW(data):\n",
    "    return skew(data)\n",
    "\n",
    "# Variance (VAR)\n",
    "def featureVAR(data):\n",
    "    variance = np.var(data)\n",
    "    return variance\n",
    "\n",
    "# AR coefficients (AR)\n",
    "def featureAR(data):\n",
    "    AR = [0.0, 0.0, 0.0, 0.0]\n",
    "    e = 0\n",
    "    method = \"mle\"\n",
    "    AR, e = sm.regression.linear_model.yule_walker(data, order=4, method=method)\n",
    "    return AR.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EDA\n",
    "def mn_eda(data):\n",
    "    return data.mean()\n",
    "\n",
    "def std_eda(data):\n",
    "    return data.std()\n",
    "    \n",
    "def max_eda(data):\n",
    "    return data.max()\n",
    "        \n",
    "def min_eda(data):\n",
    "    return data.min()\n",
    "        \n",
    "def dr_eda(data):\n",
    "    max_eda = data.max()\n",
    "    min_eda = data.min()\n",
    "    return max_eda/min_eda\n",
    "\n",
    "def max_peaks(data):\n",
    "    if (len(data) == 0):\n",
    "        return 0\n",
    "    else:\n",
    "        return np.max(data)\n",
    "\n",
    "def mean_gsr(data):\n",
    "    return np.mean(data)\n",
    "  \n",
    "def number_of_peaks(data):\n",
    "    return len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction_ECG(x_train, y_train, size):\n",
    "    features = pd.DataFrame()\n",
    "    df_x_train = pd.DataFrame()\n",
    "    new_y_train = pd.DataFrame()\n",
    "    \n",
    "    tmp_features = x_train.drop(columns=['ECG', 'EDA', 'RSP'])\n",
    "    for i in range(0, len(x_train), size):\n",
    "        x1 = featureMAV(x_train['ECG'][i:i+size])\n",
    "        x2 = featureRMS(x_train['ECG'][i:i+size])\n",
    "        x3 = featureLRMS(x_train['ECG'][i:i+size])\n",
    "        x4 = featureWL(x_train['ECG'][i:i+size])\n",
    "        x5 = featureKUR(x_train['ECG'][i:i+size])\n",
    "        x6 = featureSKEW(x_train['ECG'][i:i+size])\n",
    "        x7 = featureVAR(x_train['ECG'][i:i+size])\n",
    "        x8 = SD1overSD2(x_train['ECG'][i:i+size])\n",
    "        x9 = rmssd(x_train['ECG'][i:i+size])\n",
    "        x10 = avrr(x_train['ECG'][i:i+size])\n",
    "        x11 = csdrr(x_train['ECG'][i:i+size])\n",
    "        x12 = pNNx(x_train['ECG'][i:i+size])\n",
    "        x13 = SD2(x_train['ECG'][i:i+size])\n",
    "        x14 = CSI(x_train['ECG'][i:i+size])\n",
    "        x15 = CVI(x_train['ECG'][i:i+size])\n",
    "        x16 = modifiedCVI(x_train['ECG'][i:i+size])\n",
    "        \n",
    "        df_x_train = df_x_train.append([[x1, x2, x3, x4, x5,\n",
    "                                         x6, x7, x8, x9, x10,\n",
    "                                         x11, x11, x12, x13,\n",
    "                                         x14, x15, x16]])\n",
    "        \n",
    "        new_y_train = new_y_train.append(y_train[i+size-1:i+size])\n",
    "        \n",
    "        features = features.append(tmp_features[i+size-1:i+size])\n",
    "    \n",
    "    df_x_train = df_x_train.reset_index()\n",
    "    new_y_train = new_y_train.reset_index()\n",
    "    features = features.reset_index()\n",
    "    \n",
    "    df_x_train = df_x_train.drop(columns=['index'])\n",
    "    new_y_train = new_y_train.drop(columns=['index'])\n",
    "    features = features.drop(columns=['index'])\n",
    "    return(df_x_train, new_y_train, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction_RSP(x_train, size):\n",
    "    df_x_train = pd.DataFrame()\n",
    "    for i in range(0, len(x_train), size):\n",
    "        x1 = featureMAV(x_train['RSP'][i:i+size])\n",
    "        x2 = featureRMS(x_train['RSP'][i:i+size])\n",
    "        x3 = featureLRMS(x_train['RSP'][i:i+size])\n",
    "        x4 = featureWL(x_train['RSP'][i:i+size])\n",
    "        x5 = featureKUR(x_train['RSP'][i:i+size])\n",
    "        x6 = featureSKEW(x_train['RSP'][i:i+size])\n",
    "        x7 = featureVAR(x_train['RSP'][i:i+size])\n",
    "        \n",
    "        df_x_train = df_x_train.append([[x1, x2, x3, x4,\n",
    "                                         x5, x6, x7]])\n",
    "    \n",
    "    df_x_train = df_x_train.reset_index()\n",
    "    df_x_train = df_x_train.drop(columns=['index'])\n",
    "    return df_x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction_EDA(x_train, size):\n",
    "    df_x_train = pd.DataFrame()\n",
    "    for i in range(0, len(x_train), size):\n",
    "        x1 = mn_eda(x_train['EDA'][i:i+size])\n",
    "        x2 = std_eda(x_train['EDA'][i:i+size])\n",
    "        x3 = max_eda(x_train['EDA'][i:i+size])\n",
    "        x4 = min_eda(x_train['EDA'][i:i+size])\n",
    "        x5 = max_peaks(x_train['EDA'][i:i+size])\n",
    "        x6 = mean_gsr(x_train['EDA'][i:i+size])\n",
    "        \n",
    "        df_x_train = df_x_train.append([[x1, x2, x3,\n",
    "                                         x4, x5, x6]])\n",
    "\n",
    "    df_x_train = df_x_train.reset_index()\n",
    "    df_x_train = df_x_train.drop(columns=['index'])\n",
    "    return df_x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export(x_train, y_train, path, file):\n",
    "    x_train = x_train.reset_index()\n",
    "    y_train = y_train.reset_index()\n",
    "\n",
    "    x_train = x_train.drop(columns=['index'])\n",
    "    y_train = y_train.drop(columns=['index'])\n",
    "\n",
    "    x_train.to_csv('%s%sx' % (path, file), sep=';',header=True, index=False)\n",
    "    y_train.to_csv('%s%sy' % (path, file), sep=';',header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Call Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = load_dataset(dataset_path, train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ECG_x_train, new_y_train, features = feature_extraction_ECG(x_train, y_train, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EDA_x_train = feature_extraction_EDA(x_train, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "RSP_x_train = feature_extraction_RSP(x_train, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe created\n",
      "ecg: ok\n",
      "eda: ok\n",
      "resp: created\n",
      "features: ok\n"
     ]
    }
   ],
   "source": [
    "new_x_train = pd.DataFrame()\n",
    "print(\"dataframe created\")\n",
    "new_x_train = pd.concat([new_x_train, ECG_x_train], axis=1)\n",
    "print(\"ecg: ok\")\n",
    "new_x_train = pd.concat([new_x_train, EDA_x_train], axis=1)\n",
    "print(\"eda: ok\")\n",
    "new_x_train = pd.concat([new_x_train, RSP_x_train], axis=1)\n",
    "print(\"resp: created\")\n",
    "new_x_train = pd.concat([new_x_train, features], axis=1)\n",
    "print(\"features: ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "export(new_x_train, new_y_train, dataset_path, new_train_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
